{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of IMDB Reviews using Naive Bayes\n",
    "\n",
    "This is a much larger and more complicated dataset as compared with the Rotten Tomatoes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import nltk, the Natural Language Processing Toolkit\n",
    "\n",
    "This is one of the most popular packages for natural language processing on text data. It has APIs to access a large corpus of documents and other lexical resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.2\n",
      "3.2.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automate the download, unzip and untar of the reviews dataset\n",
    "\n",
    "The tarred and gzipped file is stored in the same directory as the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADED_FILENAME = 'ImdbReviews.tar.gz'\n",
    "\n",
    "def download_file(url_path):\n",
    "    if not os.path.exists(DOWNLOADED_FILENAME):\n",
    "        filename, _ = urllib.request.urlretrieve(url_path, DOWNLOADED_FILENAME)\n",
    "\n",
    "    print('Found and verified file from this path: ', url_path)\n",
    "    print('Downloaded file: ', DOWNLOADED_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the reviews by removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_REGEX = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "\n",
    "def get_reviews(dirname, positive=True):\n",
    "    label = 1 if positive else 0\n",
    "\n",
    "    reviews = []\n",
    "    for filename in os.listdir(dirname):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(dirname + filename, 'r+') as f:\n",
    "                review = f.read()\n",
    "                review = review.lower().replace(\"<br />\", \" \")\n",
    "                review = re.sub(TOKEN_REGEX, '', review)\n",
    "                \n",
    "                # Return a tuple of the review text and a label for whether it \n",
    "                # is a positive or negative review\n",
    "                reviews.append((review, label))\n",
    "    \n",
    "    return reviews \n",
    "\n",
    "def extract_reviews():\n",
    "    # If the file has not already been extracted\n",
    "    if not os.path.exists('aclImdb'):\n",
    "        with tarfile.open(DOWNLOADED_FILENAME) as tar:\n",
    "            tar.extractall()\n",
    "            tar.close()\n",
    "        \n",
    "    positive_reviews = get_reviews(\"aclImdb/train/pos/\", positive=True)\n",
    "    negative_reviews = get_reviews(\"aclImdb/train/neg/\", positive=False)\n",
    "    \n",
    "    return positive_reviews, negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified file from this path:  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Downloaded file:  ImdbReviews.tar.gz\n"
     ]
    }
   ],
   "source": [
    "URL_PATH = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "download_file(URL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews, negative_reviews = extract_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent episode movie ala pulp fiction 7 days  7 suicides it doesnt get more depressing than this movie rating 810 music rating 1010',\n",
       "  1),\n",
       " ('ive just read the most recent remarks about this movie and i would like to respond youre probably not familiar with the original story of rap group nwa which dates back to the beginning in 1988 in 1989 ice cube left the band to go solo and ultimately in 1991 the band breaking up when drdre left which led to a lot of beef starting with the departure of ice cube and drdre in 1991 this story was somewhat based on that  further more this movie was a 90 minute laughing spree the way they explained the bootie juice song to be a political statement was hilarious not to mention the love song tasty was hooking up and when vanilla sherbert got his ass kicked just like the record company executive is also hilarious and having theyre managers getting shot every time too  people who didnt enjoy this movie probably didnt get it or were complete idiots my opinion',\n",
       "  1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 5000\n",
    "TOTAL_DATA = 6000\n",
    "\n",
    "train_reviews = positive_reviews[:TRAIN_DATA] + negative_reviews[:TRAIN_DATA]\n",
    "\n",
    "test_positive_reviews = positive_reviews[TRAIN_DATA:TOTAL_DATA]\n",
    "test_negative_reviews = negative_reviews[TRAIN_DATA:TOTAL_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of all the unque words in the dataset, the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(train_reviews):\n",
    "    words_set = set()\n",
    "    \n",
    "    for review in train_reviews:\n",
    "        words_set.update(review[0].split())\n",
    "    \n",
    "    return list(words_set)\n",
    "\n",
    "vocabulary = get_vocabulary(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68539"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'midsomer', 'sharmas', 'condone', 'iiis']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent the words in the review as a feature vector\n",
    "\n",
    "* *review_text* The review in text form\n",
    "\n",
    "Each review is represented as a dictionary where keys are all words in the vocabulary. The values associated with each key is True if the word is present in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(review_text):\n",
    "    # Split the review into words, and create a set of the words\n",
    "    review_words = set(review_text.split())\n",
    "\n",
    "    features = {}\n",
    "    for word in vocabulary:\n",
    "        features[word] = (word in review_words)\n",
    "        \n",
    "    return features    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map feature vector to labels\n",
    "\n",
    "* *extract_features* Function to extract the features in feature vector form\n",
    "* *train_reviews* Training dataset, a list of tuples of the form (review_text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = nltk.classify.apply_features(extract_features, train_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculator(review_text):\n",
    "    features = extract_features(review_text)\n",
    "    return trained_classifier.classify(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"What an amazing movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator(\"What a terrible movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator('Light travels faster than sound. This is why some people appear bright until they speak.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator('I donâ€™t believe in plastic surgery, But in your case, Go ahead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_calculator('I am not young enough to know everything.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify and measure the accuracy of the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator):\n",
    "    positive_results = [sentiment_calculator(review[0]) for review in test_positive_reviews]\n",
    "    negative_results = [sentiment_calculator(review[0]) for review in test_negative_reviews]\n",
    "    \n",
    "    true_positives = sum(x > 0 for x in positive_results)\n",
    "    true_negatives = sum(x == 0 for x in negative_results)\n",
    "    \n",
    "    percent_true_positive = float(true_positives) / len(positive_results)\n",
    "    percent_true_negative = float(true_negatives) / len(negative_results)\n",
    "\n",
    "    total_accurate = true_positives + true_negatives\n",
    "    total = len(positive_results) + len(negative_results)\n",
    "\n",
    "    print(\"Accuracy on positive reviews = \" +\"%.2f\" % (percent_true_positive * 100) + \"%\")\n",
    "    print(\"Accurance on negative reviews = \" +\"%.2f\" % (percent_true_negative * 100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (total_accurate * 100/ total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 81.10%\n",
      "Accurance on negative reviews = 86.50%\n",
      "Overall accuracy = 83.80%\n"
     ]
    }
   ],
   "source": [
    "classify_test_reviews(test_positive_reviews, test_negative_reviews, sentiment_calculator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** D O N E ! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
